{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063e88ea",
   "metadata": {},
   "source": [
    "## DC-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "import tensorflow \n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "images1 = [cv2.resize(cv2.imread(file),(56,56)) for file in glob.glob('IMagenet/tiny-imagenet-200/val/images/*.JPEG')]\n",
    "images2t=[cv2.resize(cv2.imread(file),(56,56)) for file in glob.glob('IMagenet/tiny-imagenet-200/test/images/*.JPEG')]\n",
    "images2=images2t[:9900]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "train_images=np.vstack((images1,images2))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "images=train_images\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "plt.imshow(train_images[1],cmap='gray')\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "random_input = tensorflow.keras.layers.Input(shape = 100)\n",
    "\n",
    "x = tensorflow.keras.layers.Dense(128 * 5 * 5)(random_input)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Reshape((5, 5, 128))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3,3), strides=(2,2))(x)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3,3), strides=(2,2))(x)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3,3), strides=(2,2))(x)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(4,4))(x)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5))(x)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5))(x)\n",
    "x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(filters=3, kernel_size=(3,3))(x)\n",
    "generated_image = tensorflow.keras.layers.Activation('tanh')(x)\n",
    "\n",
    "generator_network = tensorflow.keras.models.Model(inputs=random_input, outputs=generated_image)\n",
    "generator_network.summary()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "image_input = tensorflow.keras.layers.Input(shape=(56, 56, 3))\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(filters=128, kernel_size=(3,3))(image_input)\n",
    "x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=2)(x)\n",
    "x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=2)(x)\n",
    "x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(5,5))(x)\n",
    "x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(5,5))(x)\n",
    "x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Dense(1)(x)\n",
    "real_vs_fake_output = tensorflow.keras.layers.Activation('sigmoid')(x)\n",
    "\n",
    "discriminator_network = tensorflow.keras.models.Model(inputs=image_input, outputs=real_vs_fake_output)\n",
    "discriminator_network.summary()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "discriminator_network.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "discriminator_network.trainable=False\n",
    "\n",
    "g_output = generator_network(random_input)\n",
    "d_output = discriminator_network(g_output)\n",
    "\n",
    "dcgan_model = tensorflow.keras.models.Model(random_input, d_output)\n",
    "dcgan_model.summary()\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "dcgan_model.compile(loss='binary_crossentropy', optimizer=adam_optimizer)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "indices = [i for i in range(0, len(images))]\n",
    "\n",
    "def get_random_noise(batch_size, noise_size):\n",
    "    random_values = np.random.randn(batch_size*noise_size)\n",
    "    random_noise_batch = np.reshape(random_values, (batch_size, noise_size))\n",
    "    return random_noise_batch\n",
    "\n",
    "def get_fake_samples(generator_network, batch_size, noise_size):\n",
    "    random_noise_batch = get_random_noise(batch_size, noise_size) \n",
    "    fake_samples = generator_network.predict_on_batch(random_noise_batch)\n",
    "    return fake_samples\n",
    "\n",
    "def get_real_samples(batch_size):\n",
    "    random_indices = np.random.choice(indices, size=batch_size)\n",
    "    real_images = images[np.array(random_indices),:]\n",
    "    return real_images\n",
    "\n",
    "''''def show_generator_results(generator_network):\n",
    "    for k in range(9):\n",
    "        plt.figure(figsize=(11, 11))\n",
    "        fake_samples = get_fake_samples(generator_network, 9, noise_size)\n",
    "        fake_samples = (fake_samples+1.0)/2.0\n",
    "        for j in range(9):\n",
    "            plt.subplot(990 + 1 + j)\n",
    "            plt.imshow(fake_samples[j])\n",
    "            plt.axis('off')\n",
    "            #plt.title(trainY[i])\n",
    "        plt.show()\n",
    "    return'''\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "steps = 500\n",
    "noise_size = 100\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    #if (i%10 == 0):\n",
    "        #show_generator_results(generator_network)\n",
    "    for j in range(steps):\n",
    "        fake_samples = get_fake_samples(generator_network, batch_size//2, noise_size)\n",
    "        real_samples = get_real_samples(batch_size=batch_size//2)\n",
    "\n",
    "        fake_y = np.zeros((batch_size//2, 1))\n",
    "        real_y = np.ones((batch_size//2, 1))\n",
    "        \n",
    "        input_batch = np.vstack((fake_samples, real_samples))\n",
    "        output_labels = np.vstack((fake_y, real_y))\n",
    "        \n",
    "        # Updating Discriminator weights\n",
    "        discriminator_network.trainable=True\n",
    "        loss_d = discriminator_network.train_on_batch(input_batch, output_labels)\n",
    "        \n",
    "        gan_input = get_random_noise(batch_size, noise_size)\n",
    "        \n",
    "        # Make the Discriminator belive that these are real samples and calculate loss to train the generator\n",
    "        gan_output = np.ones((batch_size))\n",
    "        \n",
    "        # Updating Generator weights\n",
    "        discriminator_network.trainable=False\n",
    "        loss_g = dcgan_model.train_on_batch(gan_input, gan_output)\n",
    "        \n",
    "        if j%50 == 0:\n",
    "            print (\"Epoch:%.0f, Step:%.0f, D-Loss:%.3f, D-Acc:%.3f, G-Loss:%.3f\"%(i,j,loss_d[0],loss_d[1]*100,loss_g))\n",
    "            \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "''''def get_random_noise(batch_size, noise_size):\n",
    "    random_values = np.random.randn(batch_size*noise_size)\n",
    "    random_noise_batch = np.reshape(random_values, (batch_size, noise_size))\n",
    "    return random_noise_batch'''\n",
    "\n",
    "y=get_random_noise(100,100)\n",
    "yx=generator_network.predict_on_batch(y)\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "def upsampler(data):\n",
    "    up_imgs=[]\n",
    "    for i in range(len(data)):\n",
    "        up_imgs.append(cv2.resize(data[i],(75,75),interpolation = cv2.INTER_AREA))\n",
    "        \n",
    "    return np.array(up_imgs)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "generated_images=upsampler(yx)\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "real_images=upsampler(images2[:100])\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "generated_images.shape, real_images.shape\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "\n",
    "model=tensorflow.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(75,75,3))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "# example of calculating the frechet inception distance\n",
    "import numpy\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy.random import random\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_fid(model,images1, images2):\n",
    "\t# calculate activations\n",
    "\tact1 = model.predict(images1)\n",
    "\tact2 = model.predict(images2)\n",
    "\t# calculate mean and covariance statistics\n",
    "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "\t# calculate sum squared difference between means\n",
    "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "\t# calculate sqrt of product between cov\n",
    "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
    "\t# check and correct imaginary numbers from sqrt\n",
    "\tif iscomplexobj(covmean):\n",
    "\t\tcovmean = covmean.real\n",
    "\t# calculate score\n",
    "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "\treturn fid\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "score=calculate_fid(model,generated_images,real_images)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "score\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "plt.imshow(yx[59])\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10)) # specifying the overall grid size\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(yx[i])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03161984",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315dfa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "latent_dim = 21\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "images1 = [cv2.cvtColor(cv2.resize(cv2.imread(file),(28,28)),cv2.COLOR_BGR2GRAY) for file in glob.glob('IMagenet/tiny-imagenet-200/val/images/*.JPEG')]\n",
    "images2t=[cv2.cvtColor(cv2.resize(cv2.imread(file),(28,28)),cv2.COLOR_BGR2GRAY) for file in glob.glob('IMagenet/tiny-imagenet-200/test/images/*.JPEG')]\n",
    "images2=images2t[:9900]\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "train_images=np.vstack((images1,images2))\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "train_images.shape\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "train_images=np.expand_dims(train_images, -1).astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "#train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "#train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "train_images.shape\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(train_images, epochs=300, batch_size=128)\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "def sampler(N):\n",
    "    generated_data=[]\n",
    "    generated_labels=[]\n",
    "    for i in range(N):\n",
    "        generated_data.append(np.random.multivariate_normal(np.zeros(21),np.identity(21)))\n",
    "    return (np.array(generated_data))    \n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "model=tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(75,75,3))\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "# example of calculating the frechet inception distance\n",
    "import numpy\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy.random import random\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_fid(model,images1, images2):\n",
    "\t# calculate activations\n",
    "\tact1 = model.predict(images1)\n",
    "\tact2 = model.predict(images2)\n",
    "\t# calculate mean and covariance statistics\n",
    "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "\t# calculate sum squared difference between means\n",
    "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "\t# calculate sqrt of product between cov\n",
    "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
    "\t# check and correct imaginary numbers from sqrt\n",
    "\tif iscomplexobj(covmean):\n",
    "\t\tcovmean = covmean.real\n",
    "\t# calculate score\n",
    "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "\treturn fid\n",
    "\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "def upsampler(data):\n",
    "    up_imgs=[]\n",
    "    for i in range(len(data)):\n",
    "        up_imgs.append(cv2.resize(data[i],(75,75),interpolation = cv2.INTER_AREA))\n",
    "        \n",
    "    return np.array(up_imgs)\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "def gray_rgb(data):\n",
    "    rgb_imgs=[]\n",
    "    for i in range(len(data)):\n",
    "        rgb_imgs.append(cv2.cvtColor(data[i],cv2.COLOR_GRAY2RGB))\n",
    "    return np.array(rgb_imgs)\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "samples=sampler(100)\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "p=decoder.predict(samples)\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "predicted_images=upsampler(p)\n",
    "\n",
    "\n",
    "# In[88]:\n",
    "\n",
    "\n",
    "predicted_images.shape\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "predicted_images=gray_rgb(predicted_images)\n",
    "\n",
    "\n",
    "# In[90]:\n",
    "\n",
    "\n",
    "predicted_images.shape\n",
    "\n",
    "\n",
    "# In[91]:\n",
    "\n",
    "\n",
    "real_images=gray_rgb(images2[:100])\n",
    "real_images=upsampler(real_images)\n",
    "\n",
    "\n",
    "# In[92]:\n",
    "\n",
    "\n",
    "score=calculate_fid(model,predicted_images,real_images)\n",
    "\n",
    "\n",
    "# In[93]:\n",
    "\n",
    "\n",
    "score\n",
    "\n",
    "\n",
    "# In[94]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(p[76])\n",
    "\n",
    "\n",
    "# In[95]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10)) # specifying the overall grid size\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)    # the number of images in the grid is 5*5 (25)\n",
    "    plt.imshow(p[i])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d83da6",
   "metadata": {},
   "source": [
    "## tSNE & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from __future__ import print_function\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import numpy.linalg as linalg\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from numpy import linalg as LA\n",
    "from skimage.util import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "\n",
    "data = load('bloodmnist.npz') \n",
    "lst = data.files \n",
    "Xtrain = data[lst[0]] \n",
    "Xtest = data[lst[1]] \n",
    "Xval = data[lst[2]] \n",
    "ytrain = data[lst[3]] \n",
    "ytest = data[lst[4]] \n",
    "yval = data[lst[5]]\n",
    "\n",
    "Xtrain = data[lst[0]]\n",
    "ytrain = data[lst[1]]\n",
    "Xval = data[lst[2]]\n",
    "yval = data[lst[3]]\n",
    "Xtest = data[lst[4]]\n",
    "ytest = data[lst[5]]\n",
    "\n",
    "print(Xtrain.shape) \n",
    "print(Xtest.shape) \n",
    "print(Xval.shape) \n",
    "print(ytrain.shape) \n",
    "print(ytest.shape) \n",
    "print(yval.shape)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "Xtrain=Xtrain.reshape(Xtrain.shape[0],2352)\n",
    "Xval=Xval.reshape(Xval.shape[0],2352)\n",
    "Xtest = Xtest.reshape(Xtest.shape[0],2352)\n",
    "print(Xtrain.shape) \n",
    "print(Xtest.shape) \n",
    "print(Xval.shape) \n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(Xtrain.shape[1]) ]\n",
    "df = pd.DataFrame(Xtrain,columns=feat_cols)\n",
    "df['y'] = ytrain\n",
    "df['label'] = df['y'].apply(lambda i: str(i))\n",
    "X, y = None, None\n",
    "print('Size of the dataframe: {}'.format(df.shape))\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "pca_50 = PCA(n_components=50)\n",
    "pca_result_50 = pca_50.fit_transform(df[feat_cols].values)\n",
    "print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n",
    "print('pca done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "df['pca-one'] = pca_result_50[:,0]\n",
    "df['pca-two'] = pca_result_50[:,1] \n",
    "df['pca-three'] = pca_result_50[:,2]\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "rndperm = np.random.permutation(df.shape[0])\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 8),\n",
    "    data=df.loc[rndperm,:],\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=df.loc[rndperm,:][\"pca-one\"], \n",
    "    ys=df.loc[rndperm,:][\"pca-two\"], \n",
    "    zs=df.loc[rndperm,:][\"pca-three\"], \n",
    "    c=df.loc[rndperm,:][\"y\"], \n",
    "    cmap='tab10'\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # tSNE\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=3, verbose=0, perplexity=40, n_iter=300)\n",
    "tsne_pca_results = tsne.fit_transform(pca_result_50)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "df['tsne-one'] = tsne_pca_results[:,0]\n",
    "df['tsne-two'] = tsne_pca_results[:,1]\n",
    "df['tsne-three'] = tsne_pca_results[:,2]\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "rndperm = np.random.permutation(df.shape[0])\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-one\", y=\"tsne-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 8),\n",
    "    data=df.loc[rndperm,:],\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=df.loc[rndperm,:][\"tsne-one\"], \n",
    "    ys=df.loc[rndperm,:][\"tsne-two\"], \n",
    "    zs=df.loc[rndperm,:][\"tsne-three\"], \n",
    "    c=df.loc[rndperm,:][\"y\"], \n",
    "    cmap='tab10'\n",
    ")\n",
    "ax.set_xlabel('tsne-one')\n",
    "ax.set_ylabel('tsne-two')\n",
    "ax.set_zlabel('tsne-three')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "data = load('bloodmnist.npz') \n",
    "lst = data.files \n",
    "Xtrain1 = data[lst[0]] \n",
    "Xtest1 = data[lst[1]] \n",
    "Xval1 = data[lst[2]] \n",
    "ytrain1 = data[lst[3]] \n",
    "ytest1 = data[lst[4]] \n",
    "yval1 = data[lst[5]]\n",
    "\n",
    "\n",
    "print(Xtrain1.shape) \n",
    "print(Xtest1.shape) \n",
    "print(Xval1.shape) \n",
    "print(ytrain1.shape) \n",
    "print(ytest1.shape) \n",
    "print(yval1.shape)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "Xtrain1[1].shape\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "io.imshow(Xtrain1[10])\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "my_image=Xtrain1[10]\n",
    "image_sum = my_image.sum(axis=2)\n",
    "print(image_sum.shape)\n",
    "\n",
    "new_image = image_sum/image_sum.max()\n",
    "print(new_image.max())\n",
    "\n",
    "#plt.figure(figsize=[12,8])\n",
    "plt.imshow(new_image, cmap=plt.cm.gray)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "newimage=\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "ipca = IncrementalPCA(n_components=20)\n",
    "image_recon = ipca.inverse_transform(ipca.fit_transform(new_image))\n",
    "\n",
    "# Plotting the reconstructed image\n",
    "#plt.figure(figsize=[12,8])\n",
    "plt.imshow(image_recon,cmap = plt.cm.gray)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
